import pandas as pd
import re
import nltk
from Pre_Processing import stopword_rem
from Pre_Processing import lemmitization

punctuations = "?:!.,;"


def compute_tf(token):
    num_of_words = len(token)

    freq = {}
    tf = {}
    for word in token:
        if word in freq:
            freq[word] += 1
        else:
            freq[word] = 1

    for value in freq:
        tf[value] = freq[value] / num_of_words

    return tf, freq


def compute_idf(doc_list):
    import math
    idf_dict = {}
    N = len(doc_list)
    # [{}, {}, {}]
    for doc in doc_list:
        for word, val in doc.items():
            if val > 0:
                if idf_dict.get(word):
                    idf_dict[word] += 1
                else:
                    idf_dict[word] = 1

    for word, val in idf_dict.items():
        idf_dict[word] = math.log(N / float(val))

    return idf_dict


def compute_tf_idf(tf_list, idf):
    for tf_dict in tf_list:
        for word in tf_dict:
            # Tf = doc[word]
            # idf = idf[word]
            tf_dict[word] = tf_dict[word] * idf[word]
    return tf_list


def output_to_csv(file_name, data_list, tweet_df=None):
    df = pd.DataFrame(data_list)
    df = df.fillna(0)
    df.index.name = "Tweet #"
    if tweet_df is not None:
        df['text'] = tweet_df['text']
        cols = df.columns.tolist()
        cols = cols[-1:] + cols[:-1]
        df = df[cols]
    df.to_csv(file_name)


def main():
    texts_list = ["it is going to rain today",
                  "today i am not going outside",
                  "i am going to watch the season premiere"]

    # corpus = ['This is the first document.',
    #           'This document is the second document.',
    #           'And this is the third one.',
    #           'Is this the first document?',
    #           ]
    # train_set = ["sky is blue", "sun is bright", "sun in the sky is bright"]

    # reviews_df = pd.read_csv("abc.csv")

    # texts_list = reviews_df['text'].tolist()

    for i in range(len(texts_list)):
        texts_list[i] = texts_list[i].lower()
        texts_list[i] = re.sub(r'\W', ' ', texts_list[i])
        texts_list[i] = re.sub(r'\s+', ' ', texts_list[i])

    all_tfs = []
    all_freqs = []
    for text in texts_list:
        token = nltk.word_tokenize(text)
        # Remove Punctuation
        for word in token:
            if word in punctuations:
                token.remove(word)

        # Lemmatization
        for i in range(len(token)):
            token[i] = lemmitization(token[i])
        tf, freq = compute_tf(token)
        all_tfs.append(tf)
        all_freqs.append(freq)

    idf = compute_idf(all_freqs)
    tfs_final = compute_tf_idf(all_tfs, idf)
    output_to_csv('tf_idf_output.csv', tfs_final, None)


if __name__ == '__main__':
    main()
